# app/app_rag.py

import streamlit as st
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chains.question_answering import load_qa_chain
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document
import os

# ğŸ”¸ ë²¡í„° ì €ì¥ì†Œ ê²½ë¡œë“¤
VECTOR_PATHS = {
    "AKI": "vector_store_aki_ko",
    "CKD": "vector_store_ckd_ko",
    "Nephrotic Syndrome": "vector_store_ns_ko",
    "Glomerulonephritis": "vector_store_gn_ko",
    "Electrolyte Disorders": "vector_store_electrolyte_ko",
}

# ğŸ”¸ ì¤‘ìš” ê²€ì‚¬ í•­ëª© ë¦¬ìŠ¤íŠ¸
TEST_ITEMS = [
    "Creatinine", "BUN", "eGFR", "Albumin", "Na", "K", "Cl", "HCO3", "Ca", "Phosphorus"
]

st.set_page_config(page_title="Nephrology RAG", layout="wide")
st.title("ğŸ§ª ì‹ ì¥ë‚´ê³¼ ì§ˆë³‘ ì˜ˆì¸¡ RAG ì‹œìŠ¤í…œ")

st.markdown("#### 1. í˜ˆì•¡ê²€ì‚¬ ìˆ˜ì¹˜ ì…ë ¥")
col1, col2 = st.columns(2)
user_inputs = {}

with col1:
    for item in TEST_ITEMS[:5]:
        user_inputs[item] = st.text_input(f"{item} ìˆ˜ì¹˜", placeholder="ì˜ˆ: 1.2")

with col2:
    for item in TEST_ITEMS[5:]:
        user_inputs[item] = st.text_input(f"{item} ìˆ˜ì¹˜", placeholder="ì˜ˆ: 3.8")

st.markdown("---")
question = st.text_area("#### 2. ìì—°ì–´ ì§ˆë¬¸ ì…ë ¥", placeholder="ì˜ˆ: ì´ ìˆ˜ì¹˜ë¡œ ë³¼ ë•Œ ì–´ë–¤ ì§ˆë³‘ ê°€ëŠ¥ì„±ì´ ìˆë‚˜ìš”?")

if st.button("ğŸ” ì§ˆì˜ ì‘ë‹µ ì‹œì‘"):
    # âœ… ë¬¸ì„œ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    embedding_model = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-nli")

    # âœ… ëª¨ë“  ì§ˆë³‘êµ°ì—ì„œ ë¬¸ì„œ ê²€ìƒ‰
    all_docs = []
    for disease, path in VECTOR_PATHS.items():
        if os.path.exists(path):
            db = FAISS.load_local(path, embedding_model)
            docs = db.similarity_search(question, k=2)
            all_docs.extend(docs)

    if not all_docs:
        st.warning("âŒ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # âœ… ì‘ë‹µ ìƒì„±
        llm = OpenAI(temperature=0.3)
        chain = load_qa_chain(llm, chain_type="stuff")
        response = chain.run(input_documents=all_docs, question=question)

        st.markdown("### ğŸ§¾ ì‘ë‹µ ê²°ê³¼")
        st.success(response)

        # âœ… ë¬¸ì„œ ì¶œì²˜ í‘œì‹œ
        st.markdown("### ğŸ“„ ì°¸ì¡°í•œ ë¬¸ì„œ (ìš”ì•½)")
        for i, doc in enumerate(all_docs):
            st.markdown(f"**{i+1}.** {doc.page_content[:300]}...")

