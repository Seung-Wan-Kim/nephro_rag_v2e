
import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI
import os

# -------------------- ë²¡í„° DB ê²½ë¡œ ìžë™ ì„ íƒ í•¨ìˆ˜ --------------------
def get_vector_path_from_question(question):
    keywords = {
        "aki": ["aki", "ê¸‰ì„±ì‹ ì†ìƒ"],
        "ckd": ["ckd", "ë§Œì„±ì‹ ì§ˆí™˜", "ë§Œì„±ì½©íŒ¥ë³‘"],
        "ns": ["nephrotic", "ì‹ ì¦í›„êµ°"],
        "gn": ["glomerulonephritis", "ì‚¬êµ¬ì²´ì‹ ì—¼"],
        "electrolyte": ["electrolyte", "ì „í•´ì§ˆ"]
    }
    folder_map = {
        "aki": "vector_store_aki_ko/",
        "ckd": "vector_store_ckd_ko/",
        "ns": "vector_store_ns_ko/",
        "gn": "vector_store_gn_ko/",
        "electrolyte": "vector_store_electrolyte_ko/"
    }
    for folder, keys in keywords.items():
        for key in keys:
            if key.lower() in question.lower():
                return folder_map[folder]
    return folder_map["aki"]

# -------------------- Streamlit UI --------------------
st.set_page_config(page_title="Nephrology RAG System", layout="wide")
st.title("ðŸ§  ì‹ ìž¥ë‚´ê³¼ ì§„ë‹¨ ì§€ì› ì‹œìŠ¤í…œ")

# ìˆ˜ì¹˜ ìž…ë ¥ ì¹¼ëŸ¼ êµ¬ì„±
st.subheader("1. í˜ˆì•¡ ê²€ì‚¬ ìˆ˜ì¹˜ ìž…ë ¥")
input_labels = [
    "BUN", "Creatinine", "eGFR", "Albumin", "Proteinuria",
    "Hb", "CRP", "Na", "K"
]

cols = st.columns(3)
user_inputs = {}
for i, label in enumerate(input_labels):
    with cols[i % 3]:
        val = st.text_input(f"{label}", key=label)
        user_inputs[label] = float(val) if val.strip() else None

# -------------------- ìˆ˜ì¹˜ ê¸°ë°˜ ê²°ê³¼ í™•ì¸ --------------------
def analyze_inputs(inputs):
    results = []
    suggestions = []

    # AKI
    if inputs["Creatinine"] and inputs["Creatinine"] >= 1.5:
        results.append(("AKI", 80))
        if not inputs["eGFR"]:
            suggestions.append("eGFR")
    # CKD
    if inputs["eGFR"] and inputs["eGFR"] < 60:
        results.append(("CKD", 85))
        if not inputs["Proteinuria"]:
            suggestions.append("Proteinuria")
    # GN
    if inputs["Proteinuria"] and inputs["Proteinuria"] >= 1.0:
        results.append(("Glomerulonephritis", 75))
    # NS
    if inputs["Proteinuria"] and inputs["Proteinuria"] > 3.5:
        if inputs["Albumin"] and inputs["Albumin"] < 3.0:
            results.append(("Nephrotic Syndrome", 90))
        else:
            results.append(("Nephrotic Syndrome", 70))
        if not inputs["Albumin"]:
            suggestions.append("Albumin")

    return results, suggestions

if st.button("ìˆ˜ì¹˜ ê¸°ë°˜ ê²°ê³¼ í™•ì¸"):
    results, suggestions = analyze_inputs(user_inputs)
    if results:
        st.markdown("### ðŸ”¬ ì§„ë‹¨ ê²°ê³¼")
        for disease, score in results:
            st.write(f"âœ… {disease} ê°€ëŠ¥ì„±: {score}%")
    else:
        st.info("â— ëª…í™•í•œ ì§„ë‹¨ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    if suggestions:
        st.warning("ðŸ“Œ ë” ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ ë‹¤ìŒ í•­ëª© ìž…ë ¥ì„ ê¶Œìž¥í•©ë‹ˆë‹¤: " + ", ".join(set(suggestions)))

# -------------------- ìžì—°ì–´ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ --------------------
st.subheader("2. ìžì—°ì–´ ì§ˆë¬¸")
query = st.text_area("ì§ˆë¬¸ì„ ìž…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ê¸‰ì„±ì‹ ì†ìƒì˜ ì •ì˜ëŠ”?")

if st.button("ìžì—°ì–´ ê¸°ë°˜ ì§ˆì˜ ê²°ê³¼ í™•ì¸") and query:
    vector_path = get_vector_path_from_question(query)

    if not (os.path.exists(os.path.join(vector_path, "index.faiss")) and os.path.exists(os.path.join(vector_path, "index.pkl"))):
        st.error(f"í•´ë‹¹ ì§ˆë³‘êµ°ì— ëŒ€í•œ ë²¡í„° ë°ì´í„°ê°€ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {vector_path}")
    else:
        embedding_model = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-nli")
        try:
            db = FAISS.load_local(vector_path, embedding_model, allow_dangerous_deserialization=True)
        except ValueError as e:
            st.error(f"FAISS ë¡œë”© ì˜¤ë¥˜: {str(e)}")
            st.stop()

        qa = RetrievalQA.from_chain_type(
            llm=ChatOpenAI(temperature=0.3, model="gpt-3.5-turbo"),
            chain_type="stuff",
            retriever=db.as_retriever()
        )
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            result = qa.run(query)
        st.markdown("#### ðŸ“˜ ë‹µë³€")
        st.write(result)

st.markdown("---")
st.markdown("ðŸ“ *ë³¸ ì‹œìŠ¤í…œì€ AKI, CKD, NS, GN ì§ˆí™˜êµ°ì„ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì¹˜ + ìžì—°ì–´ ì§ˆì˜ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.*")
