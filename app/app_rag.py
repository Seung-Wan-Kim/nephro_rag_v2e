import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chains.question_answering import load_qa_chain
from langchain.llms import OpenAI
from langchain.text_splitter import CharacterTextSplitter
from langchain.docstore.document import Document
import os

# ë²¡í„° ì €ì¥ì†Œ ê²½ë¡œ ë§¤í•‘
vector_paths = {
    "AKI": "vector_store_aki_ko",
    "CKD": "vector_store_ckd_ko",
    "NS": "vector_store_ns_ko",
    "GN": "vector_store_gn_ko",
    "Electrolyte": "vector_store_electrolyte_ko",
}

# ì„ë² ë”© ëª¨ë¸ ì •ì˜
embedding_model = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-nli")

# ì§ˆë³‘êµ° ìë™ ì¶”ë¡  (ê°„ë‹¨ í‚¤ì›Œë“œ ê¸°ë°˜)
def detect_disease_group_from_query(query):
    if "ê¸‰ì„±" in query or "AKI" in query:
        return "AKI"
    elif "ë§Œì„±" in query or "CKD" in query:
        return "CKD"
    elif "ì‹ ì¦í›„êµ°" in query or "NS" in query:
        return "NS"
    elif "ì‚¬êµ¬ì²´ì‹ ì—¼" in query or "GN" in query:
        return "GN"
    elif "ì „í•´ì§ˆ" in query or "electrolyte" in query:
        return "Electrolyte"
    else:
        return "CKD"

# Streamlit ì•± ì‹œì‘
st.title("ğŸ’‰ ì‹ ì¥ë‚´ê³¼ RAG ì§„ë‹¨ ì§€ì› ì‹œìŠ¤í…œ")

# 20ê°œ í˜ˆì•¡ê²€ì‚¬ ìˆ˜ì¹˜ ì…ë ¥ ë°›ê¸°
st.subheader("ğŸ§ª í˜ˆì•¡ê²€ì‚¬ ìˆ˜ì¹˜ ì…ë ¥")
input_values = {}
cols = st.columns(5)
test_items = [
    "BUN", "Creatinine", "BUN/Cr ratio", "eGFR", "Na",
    "K", "Cl", "CO2", "Ca", "IP",
    "Hb", "PTH", "Vitamin D", "ALP", "LDH",
    "Lactate", "Albumin", "Total Protein", "Uric Acid", "Glucose"
]

for i, item in enumerate(test_items):
    with cols[i % 5]:
        input_values[item] = st.text_input(f"{item}", key=item)

# ìì—°ì–´ ì§ˆì˜ ì…ë ¥
st.subheader("ğŸ’¬ ì§ˆì˜ ì…ë ¥")
query = st.text_area("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ê¸‰ì„± ì‹ ì†ìƒì˜ ì •ì˜ëŠ”?)")

# ë²„íŠ¼ í´ë¦­ ì‹œ ê²€ìƒ‰ ìˆ˜í–‰
if st.button("ğŸ” ì§„ë‹¨ ì •ë³´ í™•ì¸"):
    if not query:
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        # ì§ˆë³‘êµ° ìë™ ì¶”ì •
        detected_disease = detect_disease_group_from_query(query)
        vector_path = vector_paths.get(detected_disease)

        if not vector_path or not os.path.exists(f"{vector_path}/index.faiss"):
            st.error("ì„ íƒëœ ì§ˆë³‘êµ°ì˜ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ë²¡í„° DB ë¡œë“œ
            db = FAISS.load_local(vector_path, embedding_model)

            # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
            docs = db.similarity_search(query)

            # LLM ì‘ë‹µ (OpenAI API ì‚¬ìš©)
            llm = OpenAI(temperature=0.3)
            chain = load_qa_chain(llm, chain_type="stuff")
            answer = chain.run(input_documents=docs, question=query)

            st.markdown("### ğŸ“˜ ë‹µë³€")
            st.write(answer)

            st.markdown("ğŸ“ ê´€ë ¨ ë¬¸ì„œ")
            for i, doc in enumerate(docs):
                st.markdown(f"**[{i+1}]** {doc.page_content[:300]}...")
